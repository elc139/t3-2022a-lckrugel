
Options: -learner XGBClassifier -parameters tree_method='hist',n_jobs=8 -py-command python3 

=== Classifier model (full training set) ===

XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=8, num_parallel_tree=1, predictor='auto', random_state=0,
              reg_alpha=0, reg_lambda=1, ...)

Time taken to build model: 6.12 seconds

Time taken to test model on test split: 0.64 seconds

=== Error on test split ===

Correctly Classified Instances       19946               99.73   %
Incorrectly Classified Instances        54                0.27   %
Kappa statistic                          0.9946
Mean absolute error                      0.004 
Root mean squared error                  0.0462
Relative absolute error                  0.7984 %
Root relative squared error              9.241  %
Total Number of Instances            20000     


=== Detailed Accuracy By Class ===

                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class
                 0,998    0,003    0,997      0,998    0,997      0,995    1,000     1,000     c0
                 0,997    0,002    0,998      0,997    0,997      0,995    1,000     1,000     c1
Weighted Avg.    0,997    0,003    0,997      0,997    0,997      0,995    1,000     1,000     


=== Confusion Matrix ===

     a     b   <-- classified as
  9925    23 |     a = c0
    31 10021 |     b = c1

